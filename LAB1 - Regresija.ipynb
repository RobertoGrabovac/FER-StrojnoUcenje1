{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sveučilište u Zagrebu  \n",
    "Fakultet elektrotehnike i računarstva  \n",
    "  \n",
    "## Strojno učenje 1 2023/2024  \n",
    "http://www.fer.unizg.hr/predmet/struce1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "### Prva laboratorijska vježba: Linearna regresija\n",
    "\n",
    "*Verzija: 1.0\n",
    "Zadnji put ažurirano: 1. 10. 2021.*\n",
    "\n",
    "(c) 2015-2023 Jan Šnajder, Domagoj Alagić \n",
    "\n",
    "Rok za predaju: **22. listopada 2023. u 23:59h**\n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pravila predaje\n",
    "Predajom vježbe potvrđujete sljedeće točke:\n",
    "1. Niste od drugoga primili pomoć pri rješavanju vježbe;\n",
    "2. Atribuirali ste dijelove koda koji su preuzeti s interneta referencirajući ih u komentarima;\n",
    "3. Niste koristili dijelove koda s interneta koji su specifični za laboratorijsku vježbu;\n",
    "4. Niste koristili UI-asistente za kodiranje kao npr. GitHub Copilot (uključivo alate generativne UI, kao što je ChatGPT).\n",
    "\n",
    "**Povreda bilo kojeg od gornjih pravila smatra se prekršajem te povlači akademske sankcije.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upute\n",
    "\n",
    "Prva laboratorijska vježba sastoji se od sedam zadataka. U nastavku slijedite upute navedene u ćelijama s tekstom. Rješavanje vježbe svodi se na **dopunjavanje ove bilježnice**: umetanja ćelije ili više njih **ispod** teksta zadatka, pisanja odgovarajućeg kôda te evaluiranja ćelija. \n",
    "\n",
    "Osigurajte da u potpunosti **razumijete** kôd koji ste napisali. Kod predaje vježbe, morate biti u stanju na zahtjev asistenta (ili demonstratora) preinačiti i ponovno evaluirati Vaš kôd. Nadalje, morate razumjeti teorijske osnove onoga što radite, u okvirima onoga što smo obradili na predavanju. Ispod nekih zadataka možete naći i pitanja koja služe kao smjernice za bolje razumijevanje gradiva (**nemojte pisati** odgovore na pitanja u bilježnicu). Stoga se nemojte ograničiti samo na to da riješite zadatak, nego slobodno eksperimentirajte. To upravo i jest svrha ovih vježbi.\n",
    "\n",
    "Vježbe trebate raditi **samostalno**. Možete se konzultirati s drugima o načelnom načinu rješavanja, ali u konačnici morate sami odraditi vježbu. U protivnome vježba nema smisla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Učitaj osnovne biblioteke...\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Jednostavna regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadan je skup primjera $\\mathcal{D}=\\{(x^{(i)},y^{(i)})\\}_{i=1}^4 = \\{(0,4),(1,1),(2,2),(4,5)\\}$. Primjere predstavite matricom $\\mathbf{X}$ dimenzija $N\\times n$ (u ovom slučaju $4\\times 1$) i vektorom oznaka $\\textbf{y}$, dimenzija $N\\times 1$ (u ovom slučaju $4\\times 1$), na sljedeći način:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrica dizajna: \n",
      " [[0]\n",
      " [1]\n",
      " [2]\n",
      " [4]]\n",
      "Vektor oznaka: \n",
      " [4 1 2 5]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0],[1],[2],[4]])\n",
    "y = np.array([4,1,2,5])\n",
    "print(\"Matrica dizajna: \\n\", X)\n",
    "print(\"Vektor oznaka: \\n\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Proučite funkciju [`PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) iz biblioteke `sklearn` i upotrijebite je za generiranje matrice dizajna $\\mathbf{\\Phi}$ koja ne koristi preslikavanje u prostor više dimenzije (samo će svakom primjeru biti dodane *dummy* jedinice; $m=n+1$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 4.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree = 1)\n",
    "X1 = poly.fit_transform(X)\n",
    "print(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upoznajte se s modulom [`linalg`](http://docs.scipy.org/doc/numpy/reference/routines.linalg.html). Izračunajte težine $\\mathbf{w}$ modela linearne regresije kao $\\mathbf{w}=(\\mathbf{\\Phi}^\\intercal\\mathbf{\\Phi})^{-1}\\mathbf{\\Phi}^\\intercal\\mathbf{y}$. Zatim se uvjerite da isti rezultat možete dobiti izračunom pseudoinverza $\\mathbf{\\Phi}^+$ matrice dizajna, tj. $\\mathbf{w}=\\mathbf{\\Phi}^+\\mathbf{y}$, korištenjem funkcije [`pinv`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.pinv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bez koristenja funkcije pinv:  [2.2        0.45714286]\n",
      "Nakon koristenja funkcije pinv:  [2.2        0.45714286]\n"
     ]
    }
   ],
   "source": [
    "from numpy import linalg\n",
    "w = linalg.inv(X1.T@X1)@X1.T@y\n",
    "w1 = linalg.pinv(X1)@y\n",
    "print(\"Bez koristenja funkcije pinv: \", w)\n",
    "print(\"Nakon koristenja funkcije pinv: \", w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radi jasnoće, u nastavku je vektor $\\mathbf{x}$ s dodanom *dummy* jedinicom $x_0=1$ označen kao $\\tilde{\\mathbf{x}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prikažite primjere iz $\\mathcal{D}$ i funkciju $h(\\tilde{\\mathbf{x}})=\\mathbf{w}^\\intercal\\tilde{\\mathbf{x}}$. Izračunajte pogrešku učenja prema izrazu $E(h|\\mathcal{D})=\\frac{1}{2}\\sum_{i=1}^N(\\tilde{\\mathbf{y}}^{(i)} - h(\\tilde{\\mathbf{x}}^{(i)}))^2$. Možete koristiti funkciju srednje kvadratne pogreške [`mean_squared_error`]( http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) iz modula [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).\n",
    "\n",
    "**Q:** Gore definirana funkcija pogreške $E(h|\\mathcal{D})$ i funkcija srednje kvadratne pogreške nisu posve identične. U čemu je razlika? Koja je \"realnija\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  2.0428571428571427\n",
      "E(h|D) =  4.085714285714285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "h = X1@w\n",
    "plt.scatter(X, y, label=\"egzaktno\")\n",
    "plt.scatter(X, h, label=\"predvidjanje\")\n",
    "plt.plot(X, h, label=\"hipoteza\", color=\"orange\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "greska = mean_squared_error(y, h)\n",
    "print(\"MSE: \", greska)\n",
    "\n",
    "e_hd = 0\n",
    "for i in range(4):\n",
    "    e_hd += (y[i] - h[i])**2\n",
    "e_hd /= 2\n",
    "print(\"E(h|D) = \", e_hd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uvjerite se da za primjere iz $\\mathcal{D}$ težine $\\mathbf{w}$ ne možemo naći rješavanjem sustava $\\mathbf{w}=\\mathbf{\\Phi}^{-1}\\mathbf{y}$, već da nam doista treba pseudoinverz.\n",
    "\n",
    "**Q:** Zašto je to slučaj? Bi li se problem mogao riješiti preslikavanjem primjera u višu dimenziju? Ako da, bi li to uvijek funkcioniralo, neovisno o skupu primjera $\\mathcal{D}$? Pokažite na primjeru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.]\n",
      " [ 1.  1.  1.  1.]\n",
      " [ 1.  2.  4.  8.]\n",
      " [ 1.  4. 16. 64.]]\n",
      "[[ 1.          0.          0.          0.        ]\n",
      " [-1.75        2.66666667 -1.          0.08333333]\n",
      " [ 0.875      -2.          1.25       -0.125     ]\n",
      " [-0.125       0.33333333 -0.25        0.04166667]]\n",
      "w: [ 4.         -5.91666667  3.375      -0.45833333]\n"
     ]
    }
   ],
   "source": [
    "# linalg.inv(X1)@y --> \"LinAlgError: Last 2 dimensions of the array must be square\"\n",
    "\n",
    "# Mogli bismo primjere preslikati u višu dimenziju te tako dobiti linearo nezavisne vektore, odnosno matricu punog ranga\n",
    "poly1 = PolynomialFeatures(degree = 3)\n",
    "X2 = poly1.fit_transform(X)\n",
    "print(X2)\n",
    "X2_inverse = linalg.inv(X2)\n",
    "print(X2_inverse)\n",
    "print(\"w:\", X2_inverse@y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite klasu [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) iz modula [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model). Provjerite jesu li težine koje izračunava ta funkcija (dostupne pomoću atributa `coef_` i `intercept_`) jednake onima koje ste izračunali gore. Ako nisu, prilagodite kôd tako da jest.\n",
    "\n",
    "**NB:** Obratite pozornost na to kako klase [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) i [`PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) koriste pomak i osigurajte da ga ne dodajete više puta.\n",
    "\n",
    "Izračunajte predikcije modela (metoda `predict`) i uvjerite se da je pogreška učenja identična onoj koju ste ranije izračunali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koeficijenti:  [2.2        0.45714286]\n",
      "Greska:  2.042857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X, y)\n",
    "w2 = np.array([reg.intercept_, *reg.coef_])\n",
    "print(\"Koeficijenti: \", w2)\n",
    "reg_predict = reg.predict(X)\n",
    "reg_greska = mean_squared_error(y, reg_predict)\n",
    "print(\"Greska: \", reg_greska)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Polinomijalna regresija i utjecaj šuma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Razmotrimo sada regresiju na većem broju primjera. Definirajte funkciju `make_labels(X, f, noise=0)` koja uzima matricu neoznačenih primjera $\\mathbf{X}_{N\\times n}$ te generira vektor njihovih oznaka $\\mathbf{y}_{N\\times 1}$. Oznake se generiraju kao $y^{(i)} = f(x^{(i)})+\\mathcal{N}(0,\\sigma^2)$, gdje je $f:\\mathbb{R}^n\\to\\mathbb{R}$ stvarna funkcija koja je generirala podatke (koja nam je u stvarnosti nepoznata), a $\\sigma$ je standardna devijacija Gaussovog šuma, definirana parametrom `noise`. Za generiranje šuma možete koristiti funkciju [`numpy.random.normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html). \n",
    "\n",
    "Generirajte skup za učenje od $N=50$ primjera uniformno distribuiranih u intervalu $[-5,5]$ pomoću funkcije $f(x) = 5 + x -2 x^2 -5 x^3$ uz šum  $\\sigma=200$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import normal\n",
    "def make_labels(X, f, noise=0):\n",
    "    # Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_instances(x1, x2, N) :\n",
    "    return np.array([np.array([x]) for x in np.linspace(x1,x2,N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prikažite taj skup funkcijom [`scatter`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenirajte model polinomijalne regresije stupnja $d=3$. Na istom grafikonu prikažite naučeni model $h(\\mathbf{x})=\\mathbf{w}^\\intercal\\tilde{\\mathbf{x}}$ i primjere za učenje. Izračunajte pogrešku učenja modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Odabir modela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Na skupu podataka iz zadatka 2 trenirajte pet modela linearne regresije $\\mathcal{H}_d$ različite složenosti, gdje je $d$ stupanj polinoma, $d\\in\\{1,3,5,10,20\\}$. Prikažite na istome grafikonu skup za učenje i funkcije $h_d(\\mathbf{x})$ za svih pet modela (preporučujemo koristiti `plot` unutar `for` petlje). Izračunajte pogrešku učenja svakog od modela.\n",
    "\n",
    "**Q:** Koji model ima najmanju pogrešku učenja i zašto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Razdvojite skup primjera iz zadatka 2 pomoću funkcije [`model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) na skup za učenja i skup za ispitivanje u omjeru 1:1. Prikažite na jednom grafikonu pogrešku učenja i ispitnu pogrešku za modele polinomijalne regresije $\\mathcal{H}_d$, sa stupnjem polinoma $d$ u rasponu $d\\in [1,2,\\ldots,20]$. Budući da kvadratna pogreška brzo raste za veće stupnjeve polinoma, umjesto da iscrtate izravno iznose pogrešaka, iscrtajte njihove logaritme.\n",
    "\n",
    "**NB:** Podjela na skupa za učenje i skup za ispitivanje mora za svih dvadeset modela biti identična.\n",
    "\n",
    "**Q:** Je li rezultat u skladu s očekivanjima? Koji biste model odabrali i zašto?\n",
    "\n",
    "**Q:** Pokrenite iscrtavanje više puta. U čemu je problem? Bi li problem bio jednako izražen kad bismo imali više primjera? Zašto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Točnost modela ovisi o (1) njegovoj složenosti (stupanj $d$ polinoma), (2) broju primjera $N$, i (3) količini šuma. Kako biste to analizirali, nacrtajte grafikone pogrešaka kao u 3b, ali za različit $N\\in$ (trećina, dvije trećine, sve) i količine šuma $\\sigma\\in\\{100,200,500\\}$ (ukupno 9 grafikona). Upotrijebite funkciju [`subplots`](http://matplotlib.org/examples/pylab_examples/subplots_demo.html) kako biste pregledno posložili grafikone u tablicu $3\\times 3$. Podatci se generiraju na isti način kao u zadatku 2.\n",
    "\n",
    "**NB:** Pobrinite se da svi grafikoni budu generirani nad usporedivim skupovima podataka, na sljedeći način. Generirajte najprije svih 1000 primjera, podijelite ih na skupove za učenje i skupove za ispitivanje (dva skupa od po 500 primjera). Zatim i od skupa za učenje i od skupa za ispitivanje načinite tri različite verzije, svaka s drugačijom količinom šuma (ukupno 2x3=6 verzija podataka). Kako bi simulirali veličinu skupa podataka, od tih dobivenih 6 skupova podataka uzorkujte trećinu, dvije trećine i sve podatke. Time ste dobili 18 skupova podataka -- skup za učenje i za testiranje za svaki od devet grafova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q:*** Jesu li rezultati očekivani? Obrazložite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Regularizirana regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "U gornjim eksperimentima nismo koristili **regularizaciju**. Vratimo se najprije na primjer iz zadatka 1. Na primjerima iz tog zadatka izračunajte težine $\\mathbf{w}$ za polinomijalni regresijski model stupnja $d=3$ uz L2-regularizaciju (tzv. *ridge regression*), prema izrazu $\\mathbf{w}=(\\mathbf{\\Phi}^\\intercal\\mathbf{\\Phi}+\\lambda\\mathbf{I})^{-1}\\mathbf{\\Phi}^\\intercal\\mathbf{y}$. Napravite izračun težina za regularizacijske faktore $\\lambda=0$, $\\lambda=1$ i $\\lambda=10$ te usporedite dobivene težine.\n",
    "\n",
    "**Q:** Kojih je dimenzija matrica koju treba invertirati?\n",
    "\n",
    "**Q:** Po čemu se razlikuju dobivene težine i je li ta razlika očekivana? Obrazložite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite klasu [`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) iz modula [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model), koja implementira L2-regularizirani regresijski model. Parametar $\\alpha$ odgovara parametru $\\lambda$. Primijenite model na istim primjerima kao u prethodnom zadatku i ispišite težine $\\mathbf{w}$ (atributi `coef_` i `intercept_`). Ponovno, pripazite na pomak.\n",
    "\n",
    "**Q:** Jesu li težine identične onima iz zadatka 4a? Ako nisu, objasnite zašto je to tako i kako biste to popravili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\n",
    "\n",
    "Vratimo se na slučaj $N=50$ slučajno generiranih primjera iz zadatka 2. Trenirajte modele polinomijalne regresije $\\mathcal{H}_{\\lambda,d}$ za $\\lambda\\in\\{0,100\\}$ i $d\\in\\{2,10\\}$ (ukupno četiri modela). Skicirajte pripadne funkcije $h(\\mathbf{x})$ i primjere (na jednom grafikonu; preporučujemo koristiti `plot` unutar `for` petlje).\n",
    "\n",
    "**Q:** Jesu li rezultati očekivani? Obrazložite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)\n",
    "\n",
    "Kao u zadataku 3b, razdvojite primjere na skup za učenje i skup za ispitivanje u omjeru 1:1. Prikažite krivulje logaritama pogreške učenja i ispitne pogreške u ovisnosti za model $\\mathcal{H}_{d=10,\\lambda}$, podešavajući faktor regularizacije $\\lambda$ u rasponu $\\lambda\\in\\{0,1,\\dots,50\\}$.\n",
    "\n",
    "**Q:** Kojoj strani na grafikonu odgovara područje prenaučenosti, a kojoj podnaučenosti? Zašto?\n",
    "\n",
    "**Q:** Koju biste vrijednosti za $\\lambda$ izabrali na temelju ovih grafikona i zašto?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. L1-regularizacija i L2-regularizacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svrha regularizacije jest potiskivanje težina modela $\\mathbf{w}$ prema nuli, kako bi model bio što jednostavniji. Složenost modela može se okarakterizirati normom pripadnog vektora težina $\\mathbf{w}$, i to tipično L2-normom ili L1-normom. Za jednom trenirani model možemo izračunati i broj ne-nul značajki, ili L0-normu, pomoću sljedeće funkcije koja prima vektor težina $\\mathbf{w}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nonzeroes(coef, tol=1e-6): \n",
    "    return len(coef) - len(coef[np.isclose(0, coef, atol=tol)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Za ovaj zadatak upotrijebite skup za učenje i skup za testiranje iz zadatka 3b. Trenirajte modele **L2-regularizirane** polinomijalne regresije stupnja $d=5$, mijenjajući hiperparametar $\\lambda$ u rasponu $\\{1,2,\\dots,100\\}$. Za svaki od treniranih modela izračunajte L{0,1,2}-norme vektora težina $\\mathbf{w}$ te ih prikažite kao funkciju od $\\lambda$. Pripazite što točno šaljete u funkciju za izračun normi.\n",
    "\n",
    "**Q:** Objasnite oblik obiju krivulja. Hoće li krivulja za $\\|\\mathbf{w}\\|_2$ doseći nulu? Zašto? Je li to problem? Zašto?\n",
    "\n",
    "**Q:** Za $\\lambda=100$, koliki je postotak težina modela jednak nuli, odnosno koliko je model rijedak?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glavna prednost L1-regularizirane regresije (ili *LASSO regression*) nad L2-regulariziranom regresijom jest u tome što L1-regularizirana regresija rezultira **rijetkim modelima** (engl. *sparse models*), odnosno modelima kod kojih su mnoge težine pritegnute na nulu. Pokažite da je to doista tako, ponovivši gornji eksperiment s **L1-regulariziranom** regresijom, implementiranom u klasi  [`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) u modulu [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Značajke različitih skala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Često se u praksi možemo susreti sa podatcima u kojima sve značajke nisu jednakih magnituda. Primjer jednog takvog skupa je regresijski skup podataka `grades` u kojem se predviđa prosjek ocjena studenta na studiju (1--5) na temelju dvije značajke: bodova na prijamnom ispitu (1--3000) i prosjeka ocjena u srednjoj školi. Prosjek ocjena na studiju izračunat je kao težinska suma ove dvije značajke uz dodani šum.\n",
    "\n",
    "Koristite sljedeći kôd kako biste generirali ovaj skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_data_points = 500\n",
    "np.random.seed(69)\n",
    "\n",
    "# Generiraj podatke o bodovima na prijamnom ispitu koristeći normalnu razdiobu i ograniči ih na interval [1, 3000].\n",
    "exam_score = np.random.normal(loc=1500.0, scale = 500.0, size = n_data_points) \n",
    "exam_score = np.round(exam_score)\n",
    "exam_score[exam_score > 3000] = 3000\n",
    "exam_score[exam_score < 0] = 0\n",
    "\n",
    "# Generiraj podatke o ocjenama iz srednje škole koristeći normalnu razdiobu i ograniči ih na interval [1, 5].\n",
    "grade_in_highschool = np.random.normal(loc=3, scale = 2.0, size = n_data_points)\n",
    "grade_in_highschool[grade_in_highschool > 5] = 5\n",
    "grade_in_highschool[grade_in_highschool < 1] = 1\n",
    "\n",
    "# Matrica dizajna.\n",
    "grades_X = np.array([exam_score,grade_in_highschool]).T\n",
    "\n",
    "# Završno, generiraj izlazne vrijednosti.\n",
    "rand_noise = np.random.normal(loc=0.0, scale = 0.5, size = n_data_points)\n",
    "exam_influence = 0.9\n",
    "grades_y = ((exam_score / 3000.0) * (exam_influence) + (grade_in_highschool / 5.0) \\\n",
    "            * (1.0 - exam_influence)) * 5.0 + rand_noise\n",
    "grades_y[grades_y < 1] = 1\n",
    "grades_y[grades_y > 5] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iscrtajte ovisnost ciljne vrijednosti (y-os) o prvoj i o drugoj značajki (x-os). Iscrtajte dva odvojena grafa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naučite model L2-regularizirane regresije ($\\lambda = 0.01$), na podacima `grades_X` i `grades_y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sada ponovite gornji eksperiment, ali prvo skalirajte podatke `grades_X` i `grades_y` i spremite ih u varijable `grades_X_fixed` i `grades_y_fixed`. Za tu svrhu, koristite [`StandardScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Gledajući grafikone iz podzadatka (a), koja značajka bi trebala imati veću magnitudu, odnosno važnost pri predikciji prosjeka na studiju? Odgovaraju li težine Vašoj intuiciji? Objasnite.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Multikolinearnost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izradite skup podataka `grades_X_fixed_colinear` tako što ćete u skupu `grades_X_fixed` iz\n",
    "zadatka *7b* duplicirati zadnji stupac (ocjenu iz srednje škole). Time smo efektivno uveli savršenu multikolinearnost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponovno, naučite na ovom skupu L2-regularizirani model regresije ($\\lambda = 0.01$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Usporedite iznose težina s onima koje ste dobili u zadatku *7b*. Što se dogodilo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slučajno uzorkujte 50% elemenata iz skupa `grades_X_fixed_colinear` i naučite dva modela L2-regularizirane regresije, jedan s $\\lambda=0.01$ i jedan s $\\lambda=1000$). Ponovite ovaj pokus 10 puta (svaki put s drugim podskupom od 50% elemenata).  Za svaki model, ispišite dobiveni vektor težina u svih 10 ponavljanja te ispišite standardnu devijaciju vrijednosti svake od težina (ukupno šest standardnih devijacija, svaka dobivena nad 10 vrijednosti)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kako regularizacija utječe na stabilnost težina?  \n",
    "**Q:** Jesu li koeficijenti jednakih magnituda kao u prethodnom pokusu? Objasnite zašto."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
